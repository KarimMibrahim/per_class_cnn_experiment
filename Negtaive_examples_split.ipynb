{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make hot encoded with minimum 3 occuarances first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "base_datasets_path = '/cluster/storage/kibrahim/per_class_cnn_experiment/GroundTruth/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = pd.read_pickle(\"/cluster/storage/kibrahim/per_class_cnn_experiment/GroundTruth/ground_truth_track_count_vector.pkl\")\n",
    "groundtruth.replace(range(3,groundtruth.iloc[:,2:].max().max()),1,inplace=True)\n",
    "groundtruth.drop(\"playlists_count\",axis = 1 ,inplace = True)\n",
    "groundtruth.to_csv(\"/cluster/storage/kibrahim/per_class_cnn_experiment/GroundTruth/ground_truth_hot_encoded_minimum3_vector.csv\")\n",
    "groundtruth.to_pickle(\"/cluster/storage/kibrahim/per_class_cnn_experiment/GroundTruth/ground_truth_hot_encoded_minimum3_vector.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a sample ofr sleep class only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = groundtruth.columns[1:]\n",
    "label = 'sleep'\n",
    "opposite_labels = ['club','gym','dance','party','workout']\n",
    "label_songs = groundtruth[groundtruth[label] == 1]\n",
    "not_label_songs = groundtruth[(groundtruth[label] == 0) & ((groundtruth[opposite_labels] == 1).any(axis = 1)) ]\n",
    "not_label_songs = not_label_songs.sample(len(label_songs.index), random_state=1)\n",
    "\n",
    "label_groundtruth = pd.concat([label_songs,not_label_songs])\n",
    "label_groundtruth = label_groundtruth[[\"song_id\",label]]\n",
    "label_groundtruth.columns = [\"song_id\",\"binary_label\"]\n",
    "#dance_groundtruth = dance_groundtruth.astype({\"binary_label\":float})\n",
    "\n",
    "# Train test split\n",
    "seed = 0\n",
    "train, test = train_test_split(label_groundtruth, test_size=0.25,random_state = seed)\n",
    "pd.DataFrame.to_csv(label_groundtruth,\n",
    "                    os.path.join(base_datasets_path,label+\"_groundtruth_categorized.csv\"),index= False)\n",
    "pd.DataFrame.to_csv(train,os.path.join(base_datasets_path,label+\"_train_groundtruth_categorized.csv\"),index=False)\n",
    "pd.DataFrame.to_csv(test,os.path.join(base_datasets_path,label+\"_test_groundtruth_categorized.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do same thing for dance! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = groundtruth.columns[1:]\n",
    "label = 'dance'\n",
    "opposite_labels = ['chill','sleep','sad','relax','work','morning']\n",
    "label_songs = groundtruth[groundtruth[label] == 1]\n",
    "not_label_songs = groundtruth[(groundtruth[label] == 0) & ((groundtruth[opposite_labels] == 1).any(axis = 1)) ]\n",
    "#not_label_songs = not_label_songs.sample(len(label_songs.index), random_state=1)\n",
    "label_songs = label_songs.sample(len(not_label_songs.index), random_state=1)\n",
    "\n",
    "label_groundtruth = pd.concat([label_songs,not_label_songs])\n",
    "label_groundtruth = label_groundtruth[[\"song_id\",label]]\n",
    "label_groundtruth.columns = [\"song_id\",\"binary_label\"]\n",
    "#dance_groundtruth = dance_groundtruth.astype({\"binary_label\":float})\n",
    "\n",
    "# Train test split\n",
    "seed = 0\n",
    "train, test = train_test_split(label_groundtruth, test_size=0.25,random_state = seed)\n",
    "pd.DataFrame.to_csv(label_groundtruth,\n",
    "                    os.path.join(base_datasets_path,label+\"_groundtruth_categorized.csv\"),index= False)\n",
    "pd.DataFrame.to_csv(train,os.path.join(base_datasets_path,label+\"_train_groundtruth_categorized.csv\"),index=False)\n",
    "pd.DataFrame.to_csv(test,os.path.join(base_datasets_path,label+\"_test_groundtruth_categorized.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do same thing for car! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = groundtruth.columns[1:]\n",
    "label = 'car'\n",
    "opposite_labels = ['club','morning','sad','sleep','train','shower','relax']\n",
    "label_songs = groundtruth[groundtruth[label] == 1]\n",
    "not_label_songs = groundtruth[(groundtruth[label] == 0) & ((groundtruth[opposite_labels] == 1).any(axis = 1)) ]\n",
    "not_label_songs = not_label_songs.sample(len(label_songs.index), random_state=1)\n",
    "#label_songs = label_songs.sample(len(not_label_songs.index), random_state=1)\n",
    "\n",
    "label_groundtruth = pd.concat([label_songs,not_label_songs])\n",
    "label_groundtruth = label_groundtruth[[\"song_id\",label]]\n",
    "label_groundtruth.columns = [\"song_id\",\"binary_label\"]\n",
    "#dance_groundtruth = dance_groundtruth.astype({\"binary_label\":float})\n",
    "\n",
    "# Train test split\n",
    "seed = 0\n",
    "train, test = train_test_split(label_groundtruth, test_size=0.25,random_state = seed)\n",
    "pd.DataFrame.to_csv(label_groundtruth,\n",
    "                    os.path.join(base_datasets_path,label+\"_groundtruth_categorized.csv\"),index= False)\n",
    "pd.DataFrame.to_csv(train,os.path.join(base_datasets_path,label+\"_train_groundtruth_categorized.csv\"),index=False)\n",
    "pd.DataFrame.to_csv(test,os.path.join(base_datasets_path,label+\"_test_groundtruth_categorized.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all classes [not done yet] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/cluster/storage/kibrahim/per_class_classifier/GroundTruth/ground_truth_hot_vector.csv' does not exist: b'/cluster/storage/kibrahim/per_class_classifier/GroundTruth/ground_truth_hot_vector.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a6cc312082b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Loop through classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgroundtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cluster/storage/kibrahim/per_class_classifier/GroundTruth/ground_truth_hot_vector.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroundtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/storage/kibrahim/context_classification_cnn/env_tf_1.2/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/storage/kibrahim/context_classification_cnn/env_tf_1.2/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/storage/kibrahim/context_classification_cnn/env_tf_1.2/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/storage/kibrahim/context_classification_cnn/env_tf_1.2/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/storage/kibrahim/context_classification_cnn/env_tf_1.2/local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/cluster/storage/kibrahim/per_class_classifier/GroundTruth/ground_truth_hot_vector.csv' does not exist: b'/cluster/storage/kibrahim/per_class_classifier/GroundTruth/ground_truth_hot_vector.csv'"
     ]
    }
   ],
   "source": [
    "# Loop through classes\n",
    "\n",
    "###################################\n",
    "#label_groundtruthlabel_groundtruththink of the groups for each class\n",
    "###################################\n",
    "\n",
    "classes = groundtruth.columns[1:]\n",
    "for label in classes: \n",
    "    label_songs = groundtruth[groundtruth[label] == 1]\n",
    "    not_label_songs = groundtruth[groundtruth[label] == 0]\n",
    "    not_label_songs = not_label_songs.sample(len(label_songs.index), random_state=1)\n",
    "\n",
    "    label_groundtruth = pd.concat([label_songs,not_label_songs])\n",
    "    label_groundtruth = label_groundtruth[[\"song_id\",label]]\n",
    "    label_groundtruth.columns = [\"song_id\",\"binary_label\"]\n",
    "    #dance_groundtruth = dance_groundtruth.astype({\"binary_label\":float})\n",
    "\n",
    "    # Train test split\n",
    "    seed = 0\n",
    "    train, test = train_test_split(label_groundtruth, test_size=0.25,random_state = seed)\n",
    "    pd.DataFrame.to_csv(label_groundtruth,\n",
    "                        os.path.join(base_datasets_path,label+\"_groundtruth.csv\"),index= False)\n",
    "    pd.DataFrame.to_csv(train,os.path.join(base_datasets_path,label+\"_train_groundtruth.csv\"),index=False)\n",
    "    pd.DataFrame.to_csv(test,os.path.join(base_datasets_path,label+\"_test_groundtruth.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['car', 'chill', 'club', 'dance', 'gym', 'happy', 'morning', 'night',\n",
       "       'park', 'party', 'relax', 'running', 'sad', 'shower', 'sleep', 'summer',\n",
       "       'train', 'training', 'work', 'workout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    'car':\n",
    "    'chill': ['club','gym','dance','party','workout'],\n",
    "    'club': ['chill','sleep','sad','relax','work','morning'],\n",
    "    'dance': ['chill','sleep','sad','relax','work','morning'],\n",
    "    'gym': ['chill','sleep','sad','relax','work','morning'],\n",
    "    'happy':\n",
    "    'morning':\n",
    "    'night':\n",
    "    'party': ['chill','sleep','sad','relax','work','morning'],\n",
    "    'relax':\n",
    "    'running':\n",
    "    'sad':\n",
    "    'shower':\n",
    "    'sleep': ['club','gym','dance','party','workout'],\n",
    "    'summer':\n",
    "    'train':\n",
    "    'training':\n",
    "    'work':\n",
    "    'workout': ['chill','sleep','sad','relax','work','morning']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf_1.2",
   "language": "python",
   "name": "env_tf_1.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
